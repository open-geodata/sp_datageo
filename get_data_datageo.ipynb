{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "yaml"
    ]
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: DataGeo\n",
    "subtitle: Dados Espaciais\n",
    "tags: [python, jupyter, package, datageo, gis]\n",
    "image: /img/posts/datageo_icon.png\n",
    "bigimg: /img/posts/datageo_big.png\n",
    "gh-repo: michelmetran/geo_SP_DataGeo\n",
    "gh-badge: [follow, star, watch, fork]\n",
    "comments: true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# *Imports* e Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente faz-se necessário importar as bibliotecas que serão necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import zipfile\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Após isso cria-se as pastas listadas, que armazenarão as informações ao longo desse *script*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('data', 'brutos'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Usei a função abaixo para fazer *download* usando o *request*. Ainda, a função pega o nome do arquivo a partir do *Content Disposition*. Peguei a função do *post* [*Downloading Files from URLs in Python*](https://www.codementor.io/@aviaryan/downloading-files-from-urls-in-python-77q3bs0un), aonde tem outros exemplos, com outras finalidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_filename_from_cd(cd):\n",
    "    \"\"\"\n",
    "    Get filename from content-disposition\n",
    "    \"\"\"\n",
    "    if not cd:\n",
    "        return None\n",
    "    fname = re.findall('filename=(.+)', cd)\n",
    "    if len(fname) == 0:\n",
    "        return None\n",
    "    return fname[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Após isso a forma de obtenção dos dados:\n",
    "1. Acessar a página dos metadados do plano de informação e exportar, mantendo armazenadas as informações da origem desse material;\n",
    "2. Caso seja possível acessar o material cartográfica por *shapefile*, será possível tomar conhecimento disso na página dos metadados;\n",
    "3. Uma função específica procura o *link* do *shapefile* e faz o download, extração da pasta zipada.\n",
    "4. Promove-se correções na tabela de atributos e nas projeções geográficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Input dos caminhos para os metadados\n",
    "url = 'http://datageo.ambiente.sp.gov.br/geoportal/catalog/search/resource/details.page?uuid='\n",
    "id_metadados = '{74040682-561A-40B8-BB2F-E188B58088C1}'\n",
    "\n",
    "# Resultados\n",
    "url_meta = '{}{}'.format(url, id_metadados)\n",
    "print('Página com metadados:\\n{}'.format(url_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Abre a página dos metadados\n",
    "page = requests.get(url_meta)\n",
    "print('Resposta da página foi {}'.format(page))\n",
    "\n",
    "# Parser HTML\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup = soup.find_all('a', href=True)\n",
    "\n",
    "# Procura Shapefile\n",
    "for i in soup:\n",
    "    text = i.text.split(' ')\n",
    "    for j in text:\n",
    "        if j in 'Shapefile':\n",
    "            print('> Encontrei o shapefile')\n",
    "            url = i['href']\n",
    "            print('Link: {}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Download do arquivo e paga o nome a partir do content-disposition\n",
    "# Arquivo zip (shapefile) vai para a pasta de 'data/brutos'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "filename = get_filename_from_cd(r.headers.get('content-disposition'))\n",
    "open(os.path.join('data', 'brutos', filename), 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Com o nome do arquivo, é realizado o download da página dos metadados\n",
    "file_meta = filename.split('.')[0]\n",
    "r = requests.get(url_meta, allow_redirects=True)\n",
    "open(os.path.join('data', 'brutos', '{}.html'.format(file_meta)), 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Unzip\n",
    "file = os.path.join('data', 'brutos', filename)\n",
    "temp = os.path.join(os.path.dirname(file), 'temp')\n",
    "os.makedirs(temp, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Lista Arquivos\n",
    "os.listdir(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Pega o nome do shapefile PRECISA HAVER SOMENTE UM!\n",
    "shp = [i for i in os.listdir(temp) if i.endswith('.shp')]\n",
    "shp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Read shapefile\n",
    "gdf = gpd.read_file(os.path.join(temp, shp[0]))\n",
    "display(gdf.head(5))\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Reprojeta\n",
    "print(gdf.crs)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "print(gdf.crs)\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Excluí pasta temporária\n",
    "shutil.rmtree(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Função\n",
    "\n",
    "Uma vez criada uma sequencia de códigos, foi possível definir uma funão que integra todos eles, apresentada abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_datageo_shp(url_meta):\n",
    "    print('Página com metadados: {}'.format(url_meta))\n",
    "\n",
    "    # Abre a página dos metadados\n",
    "    page = requests.get(url_meta)\n",
    "    print('Resposta da página foi {}'.format(page))\n",
    "\n",
    "    # Parser HTML\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    soup = soup.find_all('a', href=True)\n",
    "\n",
    "    # Procura Shapefile\n",
    "    for i in soup:\n",
    "        text = i.text.split(' ')\n",
    "        #print(text)\n",
    "        for j in text:\n",
    "            #print(j)\n",
    "            if j in 'Shapefile':\n",
    "                print('> Encontrei o shapefile')\n",
    "                url = i['href']\n",
    "                print('Link: {}'.format(url))\n",
    "\n",
    "    # Download do arquivo e paga o nome a partir do content-disposition\n",
    "    # Arquivo zip (shapefile) vai para a pasta de 'data/brutos'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    filename = get_filename_from_cd(r.headers.get('content-disposition'))\n",
    "    open(os.path.join('data', 'brutos', filename), 'wb').write(r.content)\n",
    "\n",
    "    # Com o nome do arquivo, é realizado o download da página dos metadados\n",
    "    file_meta = filename.split('.')[0]\n",
    "    r = requests.get(url_meta, allow_redirects=True)\n",
    "    open(os.path.join('data', 'brutos', '{}.html'.format(file_meta)), 'wb').write(r.content)\n",
    "\n",
    "    # Unzip\n",
    "    file = os.path.join('data', 'brutos', filename)\n",
    "    temp = os.path.join(os.path.dirname(file), 'temp')\n",
    "    os.makedirs(temp, exist_ok=True)\n",
    "    with zipfile.ZipFile(file, 'r') as zip_ref: zip_ref.extractall(temp)\n",
    "\n",
    "    # Lista Arquivos\n",
    "    os.listdir(temp)\n",
    "\n",
    "    # Pega o nome do shapefile PRECISA HAVER SOMENTE UM!\n",
    "    shp = [i for i in os.listdir(temp) if i.endswith('.shp')]\n",
    "    a = len(shp)\n",
    "    b = shp[0]\n",
    "    print('Encontrei {} arquivos \".shp\", sendo que o primeiro deles é o \"{}\"'.format(a, b))\n",
    "\n",
    "    # Read shapefile\n",
    "    gdf = gpd.read_file(os.path.join(temp, shp[0]))\n",
    "    print(gdf.head(5))\n",
    "\n",
    "    # Reprojeta\n",
    "    print(gdf.crs)\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "    print(gdf.crs)\n",
    "    gdf.plot()\n",
    "\n",
    "    # Excluí pasta temporária\n",
    "    shutil.rmtree(temp)\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "download_datageo_shp(url_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "___\n",
    "\n",
    "# Encerramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if __name__ == '__main__':\n",
    "        main()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from traitlets.config import Config\n",
    "from nbconvert import PythonExporter\n",
    "from nbconvert.preprocessors import TagRemovePreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "filename = 'get_data_datageo.ipynb'\n",
    "notebook = os.path.join(os.getcwd(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Import the exporter\n",
    "c = Config()\n",
    "c.TagRemovePreprocessor.enabled=True\n",
    "c.ClearOutputPreprocessor.enabled=True\n",
    "c.TemplateExporter.exclude_markdown=True\n",
    "c.TemplateExporter.exclude_code_cell=False\n",
    "c.TemplateExporter.exclude_input_prompt=True\n",
    "c.TemplateExporter.exclude_output=True\n",
    "c.TemplateExporter.exclude_raw=True\n",
    "c.TagRemovePreprocessor.remove_cell_tags = ('remove_cell',)\n",
    "c.TagRemovePreprocessor.remove_input_tags = ('remove_cell',)\n",
    "c.TagRemovePreprocessor.remove_all_outputs_tags = ('remove_cell',)\n",
    "c.preprocessors = ['TagRemovePreprocessor']\n",
    "c.PythonExporter.preprocessors = ['nbconvert.preprocessors.TagRemovePreprocessor']\n",
    "\n",
    "# Configure and run out exporter\n",
    "py_exporter = PythonExporter(config=c)\n",
    "py_exporter.register_preprocessor(TagRemovePreprocessor(config=c), True)\n",
    "\n",
    "# Configure and run out exporter - returns a tuple - first element with html, second with notebook metadata\n",
    "body, metadata = PythonExporter(config=c).from_filename(notebook)\n",
    "\n",
    "# Write to output html file\n",
    "with open('{}.py'.format(filename.replace('.ipynb', '')),  'w') as f:\n",
    "    f.write(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pablocarreira-py38] *",
   "language": "python",
   "name": "conda-env-pablocarreira-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
